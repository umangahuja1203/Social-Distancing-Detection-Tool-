{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB0gUYYfXEEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "# opencv is pre-installed on colab\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ], 
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg6t6EolXUfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwCwN028XqqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!rm -r /content/frames*\n",
        "!mkdir /content/frames\n",
        "\n",
        "#specify path to video\n",
        "video = \"/content/WhatsApp Video 2020-05-31 at 12.38.13 PM.mp4\"\n",
        "\n",
        "#capture video\n",
        "cap = cv2.VideoCapture(video)\n",
        "cnt=0\n",
        "\n",
        "# Check if video file is opened successfully\n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "ret,first_frame = cap.read()\n",
        "\n",
        "#Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "    \n",
        "  # Capture frame-by-frame\n",
        "  ret, frame = cap.read()\n",
        "     \n",
        "  if ret == True:\n",
        "\n",
        "    #save each frame to folder        \n",
        "    cv2.imwrite('/content/frames'+str(cnt)+'.png', frame)\n",
        "    cnt=cnt+1\n",
        "    if(cnt==750):\n",
        "      break\n",
        "\n",
        "  # Break the loop\n",
        "  else: \n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p-v-LxqhuJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#frame rate of a video\n",
        "FPS=cap.get(cv2.CAP_PROP_FPS)\n",
        "print(FPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y79z4RRjgN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set threshold for this model\n",
        "\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkvggMiDjlHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function which return the bottom center of every bbox\n",
        "def mid_point(img,person,idx):\n",
        "  #get the coordinates\n",
        "  x1,y1,x2,y2 = person[idx]\n",
        "  _ = cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "  \n",
        "  #compute bottom center of bbox\n",
        "  x_mid = int((x1+x2)/2)\n",
        "  y_mid = int(y2)\n",
        "  mid   = (x_mid,y_mid)\n",
        "  \n",
        "  _ = cv2.circle(img, mid, 5, (0, 0, 255), -1)\n",
        "  cv2.putText(img, str(idx), mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "  \n",
        "  return mid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc0YTQ4dkFcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from scipy.spatial import distance\n",
        "def compute_distance(midpoints,num):\n",
        "  dist = np.zeros((num,num))\n",
        "  for i in range(num):\n",
        "    for j in range(i+1,num):\n",
        "      if i!=j:\n",
        "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
        "        dist[i][j]=dst\n",
        "  return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHG0NQA_kNoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "def find_closest(dist,num,thresh):\n",
        "  p1=[]\n",
        "  p2=[]\n",
        "  d=[]\n",
        "  for i in range(num):\n",
        "    for j in range(i,num):\n",
        "      if( (i!=j) & (dist[i][j]<=thresh)):\n",
        "        p1.append(i)\n",
        "        p2.append(j)\n",
        "        d.append(dist[i][j])\n",
        "  return p1,p2,d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-7UEh4kWBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_2_red(img,person,p1,p2):\n",
        "  risky = np.unique(p1+p2)\n",
        "  for i in risky:\n",
        "    x1,y1,x2,y2 = person[i]\n",
        "    _ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)  \n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9GIbN8ykngk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "\n",
        "names=os.listdir('/content/frames')\n",
        "names.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "thresh=100\n",
        "for filename in glob.glob('/content/frames*.png'):\n",
        "  \n",
        "  img = cv2.imread(filename)\n",
        "  outputs = predictor(img)\n",
        "  classes=outputs['instances'].pred_classes.cpu().numpy()\n",
        "  bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "  find = np.where(classes==0)[0]\n",
        "  person=bbox[ind]\n",
        "  midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "  num = len(midpoints)\n",
        "  dist= compute_distance(midpoints,num)\n",
        "  p1,p2,d=find_closest(dist,num,thresh)\n",
        "  #  img = change_2_red(img,person,p1,p2)\n",
        "  cv2.imwrite(filename,img)\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGGsymQWrYoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "frame_array=[]\n",
        "cnt=0\n",
        "for i in range(0,751):\n",
        "  \n",
        "  img= cv2.imread('/content/frames'+str(cnt)+'.png')\n",
        "  cnt+=1\n",
        "  frame_array.append(img)\n",
        "\n",
        "    \n",
        "  \n",
        "\n",
        "img= cv2.imread('/content/frames88.png')\n",
        "height, width, layers = img.shape\n",
        "size = (width,height)\n",
        "out = cv2.VideoWriter('sample_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
        " \n",
        "for i in range(len(frame_array)):\n",
        "\n",
        "  out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBLd4DNgxdk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
